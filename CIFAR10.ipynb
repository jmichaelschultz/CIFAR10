{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq9LMb3i-0nD"
      },
      "source": [
        "# CIFAR dataset \n",
        "\n",
        "The intention of this noteboook is purely for fun! i wanted to experiment with trying different hyperparameters on a dataset i am not familar with\n",
        "\n",
        "From Wikipedia, the free encyclopedia: \"\"\"\n",
        "\n",
        "The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research.[1][2] The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes.[3] The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class.[4]\n",
        "\n",
        "Computer algorithms for recognizing objects in photos often learn by example. CIFAR-10 is a set of images that can be used to teach a computer how to recognize objects. Since the images in CIFAR-10 are low-resolution (32x32), this dataset can allow researchers to quickly try different algorithms to see what works. Various kinds of convolutional neural networks tend to be the best at recognizing the images in CIFAR-10.\n",
        "\n",
        "CIFAR-10 is a labeled subset of the 80 million tiny images dataset. When the dataset was created, students were paid to label all of the images.[5]\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n0kmv_5w-6Vd"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sklearn\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "os.chdir(path)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "snawJDnCh2R4",
        "outputId": "d20c8730-1def-415d-9b8e-b689281dae61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9oMWpYFAZ5T"
      },
      "source": [
        "####CIFAR10 dataset.\n",
        "\n",
        "You can load it with keras.datasets.cifar10.load_data(). \n",
        "The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. \n",
        "Remember to search for the right learning rate each time you change the model's architecture or hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9k8Ui-w1_6xk"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_train = X_train_full[5000:]\n",
        "y_train = y_train_full[5000:]\n",
        "X_valid = X_train_full[:5000]\n",
        "y_valid = y_train_full[:5000]\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M16S5M1O_dMm"
      },
      "outputs": [],
      "source": [
        "### building a very large model for learning purposes. then we will mess with it to improve results \n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 activation=\"elu\",\n",
        "                                 kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzeF2a1rom2Q",
        "outputId": "a718dc7e-764d-411f-fc68-ccb266fd6c99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               307300    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 500,210\n",
            "Trainable params: 500,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJkqYfRYHc71"
      },
      "source": [
        "##### Callbacks & scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2vL3hKJLHfuC"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.1**(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(lr0=0.001, s=25)\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RTFCbnZDHmsJ"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF_GROWTHv_M",
        "outputId": "a03c3967-1ba0-4729-9090-91bff5a9ae67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1407/1407 [==============================] - 18s 10ms/step - loss: 6.0695 - accuracy: 0.1663 - val_loss: 2.2285 - val_accuracy: 0.2034\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 2.0745 - accuracy: 0.2404 - val_loss: 2.2745 - val_accuracy: 0.2178\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.9605 - accuracy: 0.2808 - val_loss: 2.0664 - val_accuracy: 0.2572\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.8877 - accuracy: 0.3087 - val_loss: 1.9183 - val_accuracy: 0.2938\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.8274 - accuracy: 0.3324 - val_loss: 1.8302 - val_accuracy: 0.3382\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7732 - accuracy: 0.3574 - val_loss: 1.8098 - val_accuracy: 0.3502\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7187 - accuracy: 0.3765 - val_loss: 1.7603 - val_accuracy: 0.3568\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6766 - accuracy: 0.3961 - val_loss: 1.6646 - val_accuracy: 0.4026\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 1.6441 - accuracy: 0.4104 - val_loss: 1.6427 - val_accuracy: 0.4074\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6136 - accuracy: 0.4200 - val_loss: 1.6816 - val_accuracy: 0.3964\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5882 - accuracy: 0.4272 - val_loss: 1.6805 - val_accuracy: 0.3964\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5664 - accuracy: 0.4377 - val_loss: 1.6155 - val_accuracy: 0.4254\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5415 - accuracy: 0.4472 - val_loss: 1.6092 - val_accuracy: 0.4286\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5216 - accuracy: 0.4518 - val_loss: 1.5927 - val_accuracy: 0.4352\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5043 - accuracy: 0.4577 - val_loss: 1.5688 - val_accuracy: 0.4314\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 1.4865 - accuracy: 0.4667 - val_loss: 1.5499 - val_accuracy: 0.4436\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4716 - accuracy: 0.4717 - val_loss: 1.5679 - val_accuracy: 0.4440\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4542 - accuracy: 0.4774 - val_loss: 1.5762 - val_accuracy: 0.4454\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4406 - accuracy: 0.4816 - val_loss: 1.5614 - val_accuracy: 0.4442\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 1.4269 - accuracy: 0.4863 - val_loss: 1.5298 - val_accuracy: 0.4554\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4170 - accuracy: 0.4905 - val_loss: 1.5856 - val_accuracy: 0.4426\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4020 - accuracy: 0.4973 - val_loss: 1.5224 - val_accuracy: 0.4628\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3871 - accuracy: 0.5041 - val_loss: 1.5771 - val_accuracy: 0.4402\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3787 - accuracy: 0.5060 - val_loss: 1.5535 - val_accuracy: 0.4510\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3673 - accuracy: 0.5097 - val_loss: 1.5119 - val_accuracy: 0.4640\n",
            "Epoch 26/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3525 - accuracy: 0.5129 - val_loss: 1.5238 - val_accuracy: 0.4490\n",
            "Epoch 27/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3443 - accuracy: 0.5162 - val_loss: 1.4936 - val_accuracy: 0.4690\n",
            "Epoch 28/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3335 - accuracy: 0.5216 - val_loss: 1.5179 - val_accuracy: 0.4656\n",
            "Epoch 29/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3234 - accuracy: 0.5240 - val_loss: 1.4873 - val_accuracy: 0.4770\n",
            "Epoch 30/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3132 - accuracy: 0.5282 - val_loss: 1.5482 - val_accuracy: 0.4624\n",
            "Epoch 31/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3053 - accuracy: 0.5294 - val_loss: 1.5052 - val_accuracy: 0.4794\n",
            "Epoch 32/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2931 - accuracy: 0.5350 - val_loss: 1.4780 - val_accuracy: 0.4794\n",
            "Epoch 33/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2849 - accuracy: 0.5363 - val_loss: 1.5344 - val_accuracy: 0.4680\n",
            "Epoch 34/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2761 - accuracy: 0.5388 - val_loss: 1.5191 - val_accuracy: 0.4702\n",
            "Epoch 35/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2681 - accuracy: 0.5453 - val_loss: 1.4753 - val_accuracy: 0.4822\n",
            "Epoch 36/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2605 - accuracy: 0.5479 - val_loss: 1.5067 - val_accuracy: 0.4766\n",
            "Epoch 37/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2497 - accuracy: 0.5512 - val_loss: 1.5068 - val_accuracy: 0.4768\n",
            "Epoch 38/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2417 - accuracy: 0.5513 - val_loss: 1.4985 - val_accuracy: 0.4810\n",
            "Epoch 39/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2321 - accuracy: 0.5557 - val_loss: 1.5091 - val_accuracy: 0.4774\n",
            "Epoch 40/1000\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 1.2248 - accuracy: 0.5588 - val_loss: 1.4972 - val_accuracy: 0.4796\n",
            "Epoch 41/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2174 - accuracy: 0.5642 - val_loss: 1.5088 - val_accuracy: 0.4832\n",
            "Epoch 42/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2056 - accuracy: 0.5647 - val_loss: 1.5069 - val_accuracy: 0.4802\n",
            "Epoch 43/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1997 - accuracy: 0.5666 - val_loss: 1.5116 - val_accuracy: 0.4762\n",
            "Epoch 44/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1920 - accuracy: 0.5713 - val_loss: 1.5705 - val_accuracy: 0.4608\n",
            "Epoch 45/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1839 - accuracy: 0.5737 - val_loss: 1.5003 - val_accuracy: 0.4842\n",
            "Epoch 46/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1777 - accuracy: 0.5763 - val_loss: 1.4963 - val_accuracy: 0.4778\n",
            "Epoch 47/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1695 - accuracy: 0.5776 - val_loss: 1.5459 - val_accuracy: 0.4712\n",
            "Epoch 48/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1600 - accuracy: 0.5799 - val_loss: 1.4908 - val_accuracy: 0.4948\n",
            "Epoch 49/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1526 - accuracy: 0.5824 - val_loss: 1.5126 - val_accuracy: 0.4822\n",
            "Epoch 50/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1455 - accuracy: 0.5858 - val_loss: 1.5471 - val_accuracy: 0.4790\n",
            "Epoch 51/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1362 - accuracy: 0.5910 - val_loss: 1.5352 - val_accuracy: 0.4744\n",
            "Epoch 52/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1289 - accuracy: 0.5946 - val_loss: 1.5407 - val_accuracy: 0.4746\n",
            "Epoch 53/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1175 - accuracy: 0.5980 - val_loss: 1.5180 - val_accuracy: 0.4876\n",
            "Epoch 54/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1160 - accuracy: 0.5974 - val_loss: 1.5683 - val_accuracy: 0.4640\n",
            "Epoch 55/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1106 - accuracy: 0.6020 - val_loss: 1.5206 - val_accuracy: 0.4882\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff79022d110>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "model.fit(X_train, y_train, epochs=1000,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ShOmOPeIJm1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f59d4d-b5ea-4b40-a208-eeec75a1b0ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 1s 2ms/step - loss: 1.4753 - accuracy: 0.4822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4752825498580933, 0.4821999967098236]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "## this allows a look at the eval of the best model \n",
        "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
        "model.evaluate(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C2h4ZYDpLhTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0965df81-2644-47a7-f825-3237dc097e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1407/1407 [==============================] - 16s 9ms/step - loss: 9.1680 - accuracy: 0.2054 - val_loss: 2.0166 - val_accuracy: 0.2422 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.9620 - accuracy: 0.2638 - val_loss: 2.0107 - val_accuracy: 0.2542 - lr: 9.1201e-04\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.9112 - accuracy: 0.2948 - val_loss: 1.9431 - val_accuracy: 0.2802 - lr: 8.3176e-04\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8815 - accuracy: 0.3082 - val_loss: 2.0640 - val_accuracy: 0.2548 - lr: 7.5858e-04\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8533 - accuracy: 0.3193 - val_loss: 1.8190 - val_accuracy: 0.3352 - lr: 6.9183e-04\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8274 - accuracy: 0.3286 - val_loss: 1.7895 - val_accuracy: 0.3352 - lr: 6.3096e-04\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7933 - accuracy: 0.3458 - val_loss: 1.8210 - val_accuracy: 0.3420 - lr: 5.7544e-04\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7589 - accuracy: 0.3598 - val_loss: 1.7317 - val_accuracy: 0.3688 - lr: 5.2481e-04\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7299 - accuracy: 0.3696 - val_loss: 1.7484 - val_accuracy: 0.3666 - lr: 4.7863e-04\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7027 - accuracy: 0.3817 - val_loss: 1.7281 - val_accuracy: 0.3596 - lr: 4.3652e-04\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6677 - accuracy: 0.3982 - val_loss: 1.6730 - val_accuracy: 0.3918 - lr: 3.9811e-04\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6403 - accuracy: 0.4086 - val_loss: 1.6780 - val_accuracy: 0.3970 - lr: 3.6308e-04\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6108 - accuracy: 0.4211 - val_loss: 1.6897 - val_accuracy: 0.3942 - lr: 3.3113e-04\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5908 - accuracy: 0.4282 - val_loss: 1.6310 - val_accuracy: 0.4144 - lr: 3.0200e-04\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5709 - accuracy: 0.4322 - val_loss: 1.6167 - val_accuracy: 0.4208 - lr: 2.7542e-04\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5461 - accuracy: 0.4453 - val_loss: 1.5974 - val_accuracy: 0.4202 - lr: 2.5119e-04\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5304 - accuracy: 0.4496 - val_loss: 1.5990 - val_accuracy: 0.4260 - lr: 2.2909e-04\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5134 - accuracy: 0.4557 - val_loss: 1.5915 - val_accuracy: 0.4336 - lr: 2.0893e-04\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4982 - accuracy: 0.4612 - val_loss: 1.5770 - val_accuracy: 0.4330 - lr: 1.9055e-04\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4823 - accuracy: 0.4676 - val_loss: 1.5880 - val_accuracy: 0.4316 - lr: 1.7378e-04\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4682 - accuracy: 0.4723 - val_loss: 1.5702 - val_accuracy: 0.4350 - lr: 1.5849e-04\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4548 - accuracy: 0.4752 - val_loss: 1.5768 - val_accuracy: 0.4364 - lr: 1.4454e-04\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4393 - accuracy: 0.4831 - val_loss: 1.5644 - val_accuracy: 0.4352 - lr: 1.3183e-04\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4321 - accuracy: 0.4858 - val_loss: 1.5624 - val_accuracy: 0.4470 - lr: 1.2023e-04\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4158 - accuracy: 0.4888 - val_loss: 1.5593 - val_accuracy: 0.4394 - lr: 1.0965e-04\n",
            "Epoch 26/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4041 - accuracy: 0.4954 - val_loss: 1.5663 - val_accuracy: 0.4386 - lr: 1.0000e-04\n",
            "Epoch 27/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3928 - accuracy: 0.4978 - val_loss: 1.5693 - val_accuracy: 0.4422 - lr: 9.1201e-05\n",
            "Epoch 28/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3835 - accuracy: 0.4998 - val_loss: 1.5545 - val_accuracy: 0.4450 - lr: 8.3176e-05\n",
            "Epoch 29/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3714 - accuracy: 0.5043 - val_loss: 1.5662 - val_accuracy: 0.4446 - lr: 7.5858e-05\n",
            "Epoch 30/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3633 - accuracy: 0.5088 - val_loss: 1.5593 - val_accuracy: 0.4468 - lr: 6.9183e-05\n",
            "Epoch 31/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3529 - accuracy: 0.5113 - val_loss: 1.5768 - val_accuracy: 0.4426 - lr: 6.3096e-05\n",
            "Epoch 32/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3441 - accuracy: 0.5142 - val_loss: 1.5748 - val_accuracy: 0.4488 - lr: 5.7544e-05\n",
            "Epoch 33/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3356 - accuracy: 0.5169 - val_loss: 1.5762 - val_accuracy: 0.4438 - lr: 5.2481e-05\n",
            "Epoch 34/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3276 - accuracy: 0.5205 - val_loss: 1.5784 - val_accuracy: 0.4532 - lr: 4.7863e-05\n",
            "Epoch 35/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3200 - accuracy: 0.5237 - val_loss: 1.5899 - val_accuracy: 0.4492 - lr: 4.3652e-05\n",
            "Epoch 36/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3144 - accuracy: 0.5241 - val_loss: 1.5913 - val_accuracy: 0.4518 - lr: 3.9811e-05\n",
            "Epoch 37/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3066 - accuracy: 0.5274 - val_loss: 1.5884 - val_accuracy: 0.4504 - lr: 3.6308e-05\n",
            "Epoch 38/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3004 - accuracy: 0.5309 - val_loss: 1.5991 - val_accuracy: 0.4470 - lr: 3.3113e-05\n",
            "Epoch 39/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2951 - accuracy: 0.5330 - val_loss: 1.5982 - val_accuracy: 0.4476 - lr: 3.0200e-05\n",
            "Epoch 40/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2891 - accuracy: 0.5354 - val_loss: 1.5990 - val_accuracy: 0.4464 - lr: 2.7542e-05\n",
            "Epoch 41/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2845 - accuracy: 0.5352 - val_loss: 1.6064 - val_accuracy: 0.4498 - lr: 2.5119e-05\n",
            "Epoch 42/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2785 - accuracy: 0.5383 - val_loss: 1.6070 - val_accuracy: 0.4456 - lr: 2.2909e-05\n",
            "Epoch 43/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2741 - accuracy: 0.5396 - val_loss: 1.6244 - val_accuracy: 0.4412 - lr: 2.0893e-05\n",
            "Epoch 44/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2705 - accuracy: 0.5402 - val_loss: 1.6160 - val_accuracy: 0.4474 - lr: 1.9055e-05\n",
            "Epoch 45/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2663 - accuracy: 0.5422 - val_loss: 1.6167 - val_accuracy: 0.4500 - lr: 1.7378e-05\n",
            "Epoch 46/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2629 - accuracy: 0.5431 - val_loss: 1.6209 - val_accuracy: 0.4432 - lr: 1.5849e-05\n",
            "Epoch 47/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2597 - accuracy: 0.5445 - val_loss: 1.6254 - val_accuracy: 0.4464 - lr: 1.4454e-05\n",
            "Epoch 48/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2565 - accuracy: 0.5464 - val_loss: 1.6267 - val_accuracy: 0.4462 - lr: 1.3183e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6e0372150>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#adding learning_rate callback \n",
        "keras.backend.clear_session()\n",
        "\n",
        "callbacks2 = [early_stopping_cb,lr_scheduler]\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 activation=\"elu\",\n",
        "                                 kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=1000,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "arhLsjwWuRmH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CIFAR10",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}