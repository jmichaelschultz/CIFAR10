{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmichaelschultz/CIFAR10/blob/main/CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq9LMb3i-0nD"
      },
      "source": [
        "# CIFAR dataset \n",
        "\n",
        "The intention of this noteboook is purely for fun! i wanted to experiment with trying different hyperparameters on a dataset i am not familar with\n",
        "\n",
        "From Wikipedia, the free encyclopedia: \"\"\"\n",
        "\n",
        "The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research.[1][2] The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes.[3] The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class.[4]\n",
        "\n",
        "Computer algorithms for recognizing objects in photos often learn by example. CIFAR-10 is a set of images that can be used to teach a computer how to recognize objects. Since the images in CIFAR-10 are low-resolution (32x32), this dataset can allow researchers to quickly try different algorithms to see what works. Various kinds of convolutional neural networks tend to be the best at recognizing the images in CIFAR-10.\n",
        "\n",
        "CIFAR-10 is a labeled subset of the 80 million tiny images dataset. When the dataset was created, students were paid to label all of the images.[5]\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n0kmv_5w-6Vd"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sklearn\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AnLwwkPSqvXC",
        "outputId": "d498b459-6aa4-43ba-b4d0-ee36f04dfedc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "os.chdir(path)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "snawJDnCh2R4",
        "outputId": "61fb5a0f-1a8d-4cdc-be73-e3718671c833"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9oMWpYFAZ5T"
      },
      "source": [
        "####CIFAR10 dataset.\n",
        "\n",
        "You can load it with keras.datasets.cifar10.load_data(). \n",
        "The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. \n",
        "Remember to search for the right learning rate each time you change the model's architecture or hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9k8Ui-w1_6xk",
        "outputId": "51fc35ee-fe47-424c-e82f-fb8ca9dabaa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_train = X_train_full[5000:]\n",
        "y_train = y_train_full[5000:]\n",
        "X_valid = X_train_full[:5000]\n",
        "y_valid = y_train_full[:5000]\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M16S5M1O_dMm"
      },
      "outputs": [],
      "source": [
        "### building a very large model for learning purposes. then we will mess with it to improve results \n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 activation=\"elu\",\n",
        "                                 kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzeF2a1rom2Q",
        "outputId": "a718dc7e-764d-411f-fc68-ccb266fd6c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               307300    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 500,210\n",
            "Trainable params: 500,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJkqYfRYHc71"
      },
      "source": [
        "##### Callbacks & scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2vL3hKJLHfuC"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.1**(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(lr0=0.00001, s=25)\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTFCbnZDHmsJ"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF_GROWTHv_M",
        "outputId": "a03c3967-1ba0-4729-9090-91bff5a9ae67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1407/1407 [==============================] - 18s 10ms/step - loss: 6.0695 - accuracy: 0.1663 - val_loss: 2.2285 - val_accuracy: 0.2034\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 2.0745 - accuracy: 0.2404 - val_loss: 2.2745 - val_accuracy: 0.2178\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.9605 - accuracy: 0.2808 - val_loss: 2.0664 - val_accuracy: 0.2572\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.8877 - accuracy: 0.3087 - val_loss: 1.9183 - val_accuracy: 0.2938\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.8274 - accuracy: 0.3324 - val_loss: 1.8302 - val_accuracy: 0.3382\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7732 - accuracy: 0.3574 - val_loss: 1.8098 - val_accuracy: 0.3502\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7187 - accuracy: 0.3765 - val_loss: 1.7603 - val_accuracy: 0.3568\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6766 - accuracy: 0.3961 - val_loss: 1.6646 - val_accuracy: 0.4026\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 1.6441 - accuracy: 0.4104 - val_loss: 1.6427 - val_accuracy: 0.4074\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6136 - accuracy: 0.4200 - val_loss: 1.6816 - val_accuracy: 0.3964\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5882 - accuracy: 0.4272 - val_loss: 1.6805 - val_accuracy: 0.3964\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5664 - accuracy: 0.4377 - val_loss: 1.6155 - val_accuracy: 0.4254\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5415 - accuracy: 0.4472 - val_loss: 1.6092 - val_accuracy: 0.4286\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5216 - accuracy: 0.4518 - val_loss: 1.5927 - val_accuracy: 0.4352\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5043 - accuracy: 0.4577 - val_loss: 1.5688 - val_accuracy: 0.4314\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 1.4865 - accuracy: 0.4667 - val_loss: 1.5499 - val_accuracy: 0.4436\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4716 - accuracy: 0.4717 - val_loss: 1.5679 - val_accuracy: 0.4440\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4542 - accuracy: 0.4774 - val_loss: 1.5762 - val_accuracy: 0.4454\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4406 - accuracy: 0.4816 - val_loss: 1.5614 - val_accuracy: 0.4442\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 1.4269 - accuracy: 0.4863 - val_loss: 1.5298 - val_accuracy: 0.4554\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4170 - accuracy: 0.4905 - val_loss: 1.5856 - val_accuracy: 0.4426\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4020 - accuracy: 0.4973 - val_loss: 1.5224 - val_accuracy: 0.4628\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3871 - accuracy: 0.5041 - val_loss: 1.5771 - val_accuracy: 0.4402\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3787 - accuracy: 0.5060 - val_loss: 1.5535 - val_accuracy: 0.4510\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3673 - accuracy: 0.5097 - val_loss: 1.5119 - val_accuracy: 0.4640\n",
            "Epoch 26/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3525 - accuracy: 0.5129 - val_loss: 1.5238 - val_accuracy: 0.4490\n",
            "Epoch 27/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3443 - accuracy: 0.5162 - val_loss: 1.4936 - val_accuracy: 0.4690\n",
            "Epoch 28/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3335 - accuracy: 0.5216 - val_loss: 1.5179 - val_accuracy: 0.4656\n",
            "Epoch 29/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3234 - accuracy: 0.5240 - val_loss: 1.4873 - val_accuracy: 0.4770\n",
            "Epoch 30/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3132 - accuracy: 0.5282 - val_loss: 1.5482 - val_accuracy: 0.4624\n",
            "Epoch 31/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3053 - accuracy: 0.5294 - val_loss: 1.5052 - val_accuracy: 0.4794\n",
            "Epoch 32/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2931 - accuracy: 0.5350 - val_loss: 1.4780 - val_accuracy: 0.4794\n",
            "Epoch 33/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2849 - accuracy: 0.5363 - val_loss: 1.5344 - val_accuracy: 0.4680\n",
            "Epoch 34/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2761 - accuracy: 0.5388 - val_loss: 1.5191 - val_accuracy: 0.4702\n",
            "Epoch 35/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2681 - accuracy: 0.5453 - val_loss: 1.4753 - val_accuracy: 0.4822\n",
            "Epoch 36/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2605 - accuracy: 0.5479 - val_loss: 1.5067 - val_accuracy: 0.4766\n",
            "Epoch 37/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2497 - accuracy: 0.5512 - val_loss: 1.5068 - val_accuracy: 0.4768\n",
            "Epoch 38/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2417 - accuracy: 0.5513 - val_loss: 1.4985 - val_accuracy: 0.4810\n",
            "Epoch 39/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2321 - accuracy: 0.5557 - val_loss: 1.5091 - val_accuracy: 0.4774\n",
            "Epoch 40/1000\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 1.2248 - accuracy: 0.5588 - val_loss: 1.4972 - val_accuracy: 0.4796\n",
            "Epoch 41/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2174 - accuracy: 0.5642 - val_loss: 1.5088 - val_accuracy: 0.4832\n",
            "Epoch 42/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2056 - accuracy: 0.5647 - val_loss: 1.5069 - val_accuracy: 0.4802\n",
            "Epoch 43/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1997 - accuracy: 0.5666 - val_loss: 1.5116 - val_accuracy: 0.4762\n",
            "Epoch 44/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1920 - accuracy: 0.5713 - val_loss: 1.5705 - val_accuracy: 0.4608\n",
            "Epoch 45/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1839 - accuracy: 0.5737 - val_loss: 1.5003 - val_accuracy: 0.4842\n",
            "Epoch 46/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1777 - accuracy: 0.5763 - val_loss: 1.4963 - val_accuracy: 0.4778\n",
            "Epoch 47/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1695 - accuracy: 0.5776 - val_loss: 1.5459 - val_accuracy: 0.4712\n",
            "Epoch 48/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1600 - accuracy: 0.5799 - val_loss: 1.4908 - val_accuracy: 0.4948\n",
            "Epoch 49/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1526 - accuracy: 0.5824 - val_loss: 1.5126 - val_accuracy: 0.4822\n",
            "Epoch 50/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1455 - accuracy: 0.5858 - val_loss: 1.5471 - val_accuracy: 0.4790\n",
            "Epoch 51/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1362 - accuracy: 0.5910 - val_loss: 1.5352 - val_accuracy: 0.4744\n",
            "Epoch 52/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1289 - accuracy: 0.5946 - val_loss: 1.5407 - val_accuracy: 0.4746\n",
            "Epoch 53/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1175 - accuracy: 0.5980 - val_loss: 1.5180 - val_accuracy: 0.4876\n",
            "Epoch 54/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1160 - accuracy: 0.5974 - val_loss: 1.5683 - val_accuracy: 0.4640\n",
            "Epoch 55/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1106 - accuracy: 0.6020 - val_loss: 1.5206 - val_accuracy: 0.4882\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff79022d110>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "model.fit(X_train, y_train, epochs=1000,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShOmOPeIJm1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f59d4d-b5ea-4b40-a208-eeec75a1b0ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 1s 2ms/step - loss: 1.4753 - accuracy: 0.4822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4752825498580933, 0.4821999967098236]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "## this allows a look at the eval of the best model \n",
        "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
        "model.evaluate(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2h4ZYDpLhTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0965df81-2644-47a7-f825-3237dc097e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1407/1407 [==============================] - 16s 9ms/step - loss: 9.1680 - accuracy: 0.2054 - val_loss: 2.0166 - val_accuracy: 0.2422 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.9620 - accuracy: 0.2638 - val_loss: 2.0107 - val_accuracy: 0.2542 - lr: 9.1201e-04\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.9112 - accuracy: 0.2948 - val_loss: 1.9431 - val_accuracy: 0.2802 - lr: 8.3176e-04\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8815 - accuracy: 0.3082 - val_loss: 2.0640 - val_accuracy: 0.2548 - lr: 7.5858e-04\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8533 - accuracy: 0.3193 - val_loss: 1.8190 - val_accuracy: 0.3352 - lr: 6.9183e-04\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8274 - accuracy: 0.3286 - val_loss: 1.7895 - val_accuracy: 0.3352 - lr: 6.3096e-04\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7933 - accuracy: 0.3458 - val_loss: 1.8210 - val_accuracy: 0.3420 - lr: 5.7544e-04\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7589 - accuracy: 0.3598 - val_loss: 1.7317 - val_accuracy: 0.3688 - lr: 5.2481e-04\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7299 - accuracy: 0.3696 - val_loss: 1.7484 - val_accuracy: 0.3666 - lr: 4.7863e-04\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7027 - accuracy: 0.3817 - val_loss: 1.7281 - val_accuracy: 0.3596 - lr: 4.3652e-04\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6677 - accuracy: 0.3982 - val_loss: 1.6730 - val_accuracy: 0.3918 - lr: 3.9811e-04\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6403 - accuracy: 0.4086 - val_loss: 1.6780 - val_accuracy: 0.3970 - lr: 3.6308e-04\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6108 - accuracy: 0.4211 - val_loss: 1.6897 - val_accuracy: 0.3942 - lr: 3.3113e-04\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5908 - accuracy: 0.4282 - val_loss: 1.6310 - val_accuracy: 0.4144 - lr: 3.0200e-04\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5709 - accuracy: 0.4322 - val_loss: 1.6167 - val_accuracy: 0.4208 - lr: 2.7542e-04\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5461 - accuracy: 0.4453 - val_loss: 1.5974 - val_accuracy: 0.4202 - lr: 2.5119e-04\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5304 - accuracy: 0.4496 - val_loss: 1.5990 - val_accuracy: 0.4260 - lr: 2.2909e-04\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5134 - accuracy: 0.4557 - val_loss: 1.5915 - val_accuracy: 0.4336 - lr: 2.0893e-04\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4982 - accuracy: 0.4612 - val_loss: 1.5770 - val_accuracy: 0.4330 - lr: 1.9055e-04\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4823 - accuracy: 0.4676 - val_loss: 1.5880 - val_accuracy: 0.4316 - lr: 1.7378e-04\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4682 - accuracy: 0.4723 - val_loss: 1.5702 - val_accuracy: 0.4350 - lr: 1.5849e-04\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4548 - accuracy: 0.4752 - val_loss: 1.5768 - val_accuracy: 0.4364 - lr: 1.4454e-04\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4393 - accuracy: 0.4831 - val_loss: 1.5644 - val_accuracy: 0.4352 - lr: 1.3183e-04\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4321 - accuracy: 0.4858 - val_loss: 1.5624 - val_accuracy: 0.4470 - lr: 1.2023e-04\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4158 - accuracy: 0.4888 - val_loss: 1.5593 - val_accuracy: 0.4394 - lr: 1.0965e-04\n",
            "Epoch 26/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4041 - accuracy: 0.4954 - val_loss: 1.5663 - val_accuracy: 0.4386 - lr: 1.0000e-04\n",
            "Epoch 27/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3928 - accuracy: 0.4978 - val_loss: 1.5693 - val_accuracy: 0.4422 - lr: 9.1201e-05\n",
            "Epoch 28/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3835 - accuracy: 0.4998 - val_loss: 1.5545 - val_accuracy: 0.4450 - lr: 8.3176e-05\n",
            "Epoch 29/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3714 - accuracy: 0.5043 - val_loss: 1.5662 - val_accuracy: 0.4446 - lr: 7.5858e-05\n",
            "Epoch 30/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3633 - accuracy: 0.5088 - val_loss: 1.5593 - val_accuracy: 0.4468 - lr: 6.9183e-05\n",
            "Epoch 31/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3529 - accuracy: 0.5113 - val_loss: 1.5768 - val_accuracy: 0.4426 - lr: 6.3096e-05\n",
            "Epoch 32/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3441 - accuracy: 0.5142 - val_loss: 1.5748 - val_accuracy: 0.4488 - lr: 5.7544e-05\n",
            "Epoch 33/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3356 - accuracy: 0.5169 - val_loss: 1.5762 - val_accuracy: 0.4438 - lr: 5.2481e-05\n",
            "Epoch 34/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3276 - accuracy: 0.5205 - val_loss: 1.5784 - val_accuracy: 0.4532 - lr: 4.7863e-05\n",
            "Epoch 35/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3200 - accuracy: 0.5237 - val_loss: 1.5899 - val_accuracy: 0.4492 - lr: 4.3652e-05\n",
            "Epoch 36/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3144 - accuracy: 0.5241 - val_loss: 1.5913 - val_accuracy: 0.4518 - lr: 3.9811e-05\n",
            "Epoch 37/1000\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3066 - accuracy: 0.5274 - val_loss: 1.5884 - val_accuracy: 0.4504 - lr: 3.6308e-05\n",
            "Epoch 38/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3004 - accuracy: 0.5309 - val_loss: 1.5991 - val_accuracy: 0.4470 - lr: 3.3113e-05\n",
            "Epoch 39/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2951 - accuracy: 0.5330 - val_loss: 1.5982 - val_accuracy: 0.4476 - lr: 3.0200e-05\n",
            "Epoch 40/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2891 - accuracy: 0.5354 - val_loss: 1.5990 - val_accuracy: 0.4464 - lr: 2.7542e-05\n",
            "Epoch 41/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2845 - accuracy: 0.5352 - val_loss: 1.6064 - val_accuracy: 0.4498 - lr: 2.5119e-05\n",
            "Epoch 42/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2785 - accuracy: 0.5383 - val_loss: 1.6070 - val_accuracy: 0.4456 - lr: 2.2909e-05\n",
            "Epoch 43/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2741 - accuracy: 0.5396 - val_loss: 1.6244 - val_accuracy: 0.4412 - lr: 2.0893e-05\n",
            "Epoch 44/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2705 - accuracy: 0.5402 - val_loss: 1.6160 - val_accuracy: 0.4474 - lr: 1.9055e-05\n",
            "Epoch 45/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2663 - accuracy: 0.5422 - val_loss: 1.6167 - val_accuracy: 0.4500 - lr: 1.7378e-05\n",
            "Epoch 46/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2629 - accuracy: 0.5431 - val_loss: 1.6209 - val_accuracy: 0.4432 - lr: 1.5849e-05\n",
            "Epoch 47/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2597 - accuracy: 0.5445 - val_loss: 1.6254 - val_accuracy: 0.4464 - lr: 1.4454e-05\n",
            "Epoch 48/1000\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2565 - accuracy: 0.5464 - val_loss: 1.6267 - val_accuracy: 0.4462 - lr: 1.3183e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6e0372150>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#adding learning_rate callback \n",
        "keras.backend.clear_session()\n",
        "\n",
        "callbacks2 = [early_stopping_cb,lr_scheduler]\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 activation=\"elu\",\n",
        "                                 kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=1000,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "arhLsjwWuRmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solving this problem the right way.\n",
        "\n",
        "###### in the readme i mentioned that the real solution to this problem is likely building a CNN. I will show that to be true by using transfer learning on a CNN\n"
      ],
      "metadata": {
        "id": "ZYl-hDqcq3De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "Ffdb3rpGrKld",
        "outputId": "030a398f-b14d-4e52-afa5-f8a433c631a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_cat = tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
        "y_valid_cat = tf.keras.utils.to_categorical(y_valid,num_classes=10)\n",
        "\n",
        "y_train_cat.shape"
      ],
      "metadata": {
        "id": "No21TEj3rOwp",
        "outputId": "b74ab788-2562-42d8-b270-16efe5644c0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19 = tf.keras.applications.VGG19(include_top=False,weights=\"imagenet\",input_shape=(32,32,3))"
      ],
      "metadata": {
        "id": "xXlOLt4hr8fi",
        "outputId": "e697ee52-9111-4fc7-ad0e-5d33d286ff94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "for layer in vgg19.layers:\n",
        "    model.add(layer)\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(512))\n",
        "model.add(keras.layers.Dense(256))\n",
        "model.add(keras.layers.Dense(128))\n",
        "model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7w9N0-pusrmi",
        "outputId": "aa9bb01f-ce6b-4212-b605-00c45b2b2e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,452,554\n",
            "Trainable params: 428,170\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate= .001), loss = 'categorical_crossentropy', metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "5WcV1SBTt1CY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_train, y_train_cat, epochs=1000,\n",
        "          validation_data=(X_valid, y_valid_cat),\n",
        "          callbacks=[tensorboard_cb, early_stopping_cb, model_checkpoint_cb])"
      ],
      "metadata": {
        "id": "pxSE__JYuM3s",
        "outputId": "70a6d72a-0ec2-403e-cb03-e503bdf427d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4903 - accuracy: 0.5192 - val_loss: 1.4504 - val_accuracy: 0.5252\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3584 - accuracy: 0.5385 - val_loss: 1.3143 - val_accuracy: 0.5538\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3481 - accuracy: 0.5438 - val_loss: 1.3936 - val_accuracy: 0.5252\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3501 - accuracy: 0.5409 - val_loss: 1.4486 - val_accuracy: 0.5118\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3263 - accuracy: 0.5452 - val_loss: 1.3340 - val_accuracy: 0.5444\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2919 - accuracy: 0.5563 - val_loss: 1.3015 - val_accuracy: 0.5568\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2708 - accuracy: 0.5603 - val_loss: 1.2886 - val_accuracy: 0.5620\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2528 - accuracy: 0.5666 - val_loss: 1.2694 - val_accuracy: 0.5688\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2409 - accuracy: 0.5739 - val_loss: 1.2714 - val_accuracy: 0.5768\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2340 - accuracy: 0.5757 - val_loss: 1.2930 - val_accuracy: 0.5668\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2236 - accuracy: 0.5777 - val_loss: 1.2592 - val_accuracy: 0.5664\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2170 - accuracy: 0.5808 - val_loss: 1.3185 - val_accuracy: 0.5528\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2151 - accuracy: 0.5820 - val_loss: 1.2818 - val_accuracy: 0.5574\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2034 - accuracy: 0.5834 - val_loss: 1.2506 - val_accuracy: 0.5776\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2076 - accuracy: 0.5874 - val_loss: 1.2351 - val_accuracy: 0.5792\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2002 - accuracy: 0.5872 - val_loss: 1.3520 - val_accuracy: 0.5608\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2002 - accuracy: 0.5878 - val_loss: 1.2349 - val_accuracy: 0.5772\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1980 - accuracy: 0.5867 - val_loss: 1.2564 - val_accuracy: 0.5722\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1983 - accuracy: 0.5867 - val_loss: 1.2578 - val_accuracy: 0.5702\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1929 - accuracy: 0.5902 - val_loss: 1.2477 - val_accuracy: 0.5758\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1933 - accuracy: 0.5882 - val_loss: 1.2465 - val_accuracy: 0.5712\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1928 - accuracy: 0.5897 - val_loss: 1.2818 - val_accuracy: 0.5684\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1929 - accuracy: 0.5880 - val_loss: 1.2158 - val_accuracy: 0.5860\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1897 - accuracy: 0.5905 - val_loss: 1.2567 - val_accuracy: 0.5758\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1899 - accuracy: 0.5916 - val_loss: 1.2753 - val_accuracy: 0.5676\n",
            "Epoch 26/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1887 - accuracy: 0.5890 - val_loss: 1.2409 - val_accuracy: 0.5776\n",
            "Epoch 27/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1919 - accuracy: 0.5880 - val_loss: 1.2362 - val_accuracy: 0.5768\n",
            "Epoch 28/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1888 - accuracy: 0.5888 - val_loss: 1.2805 - val_accuracy: 0.5684\n",
            "Epoch 29/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1847 - accuracy: 0.5908 - val_loss: 1.2916 - val_accuracy: 0.5672\n",
            "Epoch 30/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1862 - accuracy: 0.5892 - val_loss: 1.2495 - val_accuracy: 0.5796\n",
            "Epoch 31/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1863 - accuracy: 0.5904 - val_loss: 1.2733 - val_accuracy: 0.5644\n",
            "Epoch 32/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1829 - accuracy: 0.5900 - val_loss: 1.2563 - val_accuracy: 0.5774\n",
            "Epoch 33/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1849 - accuracy: 0.5908 - val_loss: 1.2377 - val_accuracy: 0.5862\n",
            "Epoch 34/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1842 - accuracy: 0.5903 - val_loss: 1.2491 - val_accuracy: 0.5780\n",
            "Epoch 35/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1850 - accuracy: 0.5921 - val_loss: 1.2622 - val_accuracy: 0.5668\n",
            "Epoch 36/1000\n",
            "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1845 - accuracy: 0.5924 - val_loss: 1.2233 - val_accuracy: 0.5830\n",
            "Epoch 37/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1837 - accuracy: 0.5899 - val_loss: 1.2418 - val_accuracy: 0.5794\n",
            "Epoch 38/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1856 - accuracy: 0.5897 - val_loss: 1.2591 - val_accuracy: 0.5762\n",
            "Epoch 39/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1844 - accuracy: 0.5912 - val_loss: 1.3046 - val_accuracy: 0.5664\n",
            "Epoch 40/1000\n",
            "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1804 - accuracy: 0.5907 - val_loss: 1.2599 - val_accuracy: 0.5792\n",
            "Epoch 41/1000\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1829 - accuracy: 0.5913 - val_loss: 1.2846 - val_accuracy: 0.5602\n",
            "Epoch 42/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1833 - accuracy: 0.5900 - val_loss: 1.2539 - val_accuracy: 0.5816\n",
            "Epoch 43/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1807 - accuracy: 0.5930 - val_loss: 1.2874 - val_accuracy: 0.5742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(hist.history).plot(figsize = (8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2dP3wuTuw8BK",
        "outputId": "4936a1e1-616d-48d8-b523-37325610cc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### the top layers should be fairly well trained. unfreezing bottom layers. lowering learning rate and continuing training\n",
        "for layer in model.layers: \n",
        "  layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate= .00001), loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
        "history = model.fit(X_train, y_train_cat, epochs=1000,\n",
        "          validation_data=(X_valid, y_valid_cat),\n",
        "          callbacks=[tensorboard_cb, early_stopping_cb, model_checkpoint_cb])"
      ],
      "metadata": {
        "id": "5nMqzkMBxNT7",
        "outputId": "47aea30b-5390-4308-e62a-0125a9f01a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1407/1407 [==============================] - 40s 27ms/step - loss: 0.8418 - accuracy: 0.7107 - val_loss: 0.6641 - val_accuracy: 0.7704\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 38s 27ms/step - loss: 0.5639 - accuracy: 0.8049 - val_loss: 0.5771 - val_accuracy: 0.8124\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 38s 27ms/step - loss: 0.4235 - accuracy: 0.8504 - val_loss: 0.5698 - val_accuracy: 0.8142\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.3153 - accuracy: 0.8888 - val_loss: 0.5835 - val_accuracy: 0.8196\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 37s 27ms/step - loss: 0.2242 - accuracy: 0.9200 - val_loss: 0.5499 - val_accuracy: 0.8314\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.1584 - accuracy: 0.9449 - val_loss: 0.6020 - val_accuracy: 0.8268\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.1115 - accuracy: 0.9612 - val_loss: 0.6895 - val_accuracy: 0.8260\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.0849 - accuracy: 0.9709 - val_loss: 0.7313 - val_accuracy: 0.8248\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.0683 - accuracy: 0.9762 - val_loss: 0.7036 - val_accuracy: 0.8248\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0574 - accuracy: 0.9803 - val_loss: 0.9753 - val_accuracy: 0.8196\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0495 - accuracy: 0.9840 - val_loss: 0.8232 - val_accuracy: 0.8244\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0461 - accuracy: 0.9852 - val_loss: 0.8420 - val_accuracy: 0.8218\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0383 - accuracy: 0.9873 - val_loss: 0.8302 - val_accuracy: 0.8314\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 0.8267 - val_accuracy: 0.8366\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.0340 - accuracy: 0.9888 - val_loss: 0.8013 - val_accuracy: 0.8336\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.8606 - val_accuracy: 0.8456\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.0294 - accuracy: 0.9898 - val_loss: 0.8843 - val_accuracy: 0.8388\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.0296 - accuracy: 0.9907 - val_loss: 0.8961 - val_accuracy: 0.8200\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 1.0360 - val_accuracy: 0.8206\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.8843 - val_accuracy: 0.8362\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.8872 - val_accuracy: 0.8412\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 1.0201 - val_accuracy: 0.8226\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.8636 - val_accuracy: 0.8376\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.9321 - val_accuracy: 0.8294\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.9082 - val_accuracy: 0.8346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### its very clear that this solution is much better than a DNN at solving this issue. 83% validation accuaracy is not bad. lets add augment the data to see the effect.\n",
        "## i expect it will add some noise to the training loss but hopefully will give an improvement on validation as a result of gerneralization \n",
        "\n",
        "generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1) \n",
        "\n",
        "#including exp lr_weight decay \n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate= .00001), loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
        "history = model.fit(generator.flow(X_train, y_train_cat), epochs=1000,\n",
        "          validation_data=(X_valid, y_valid_cat),\n",
        "          callbacks=[tensorboard_cb, early_stopping_cb, model_checkpoint_cb, lr_scheduler])"
      ],
      "metadata": {
        "id": "pVu74BHWzLx1",
        "outputId": "b1ded99e-c09b-4d4f-f6f8-baf563738cfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1407/1407 [==============================] - 40s 28ms/step - loss: 0.2495 - accuracy: 0.9219 - val_loss: 0.5448 - val_accuracy: 0.8460 - lr: 1.0000e-05\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 39s 27ms/step - loss: 0.1777 - accuracy: 0.9435 - val_loss: 0.5421 - val_accuracy: 0.8482 - lr: 9.1201e-06\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 39s 27ms/step - loss: 0.1371 - accuracy: 0.9547 - val_loss: 0.5407 - val_accuracy: 0.8454 - lr: 8.3176e-06\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.1103 - accuracy: 0.9649 - val_loss: 0.5722 - val_accuracy: 0.8504 - lr: 7.5858e-06\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0824 - accuracy: 0.9735 - val_loss: 0.6417 - val_accuracy: 0.8540 - lr: 6.9183e-06\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.0700 - accuracy: 0.9774 - val_loss: 0.6441 - val_accuracy: 0.8542 - lr: 6.3096e-06\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0562 - accuracy: 0.9818 - val_loss: 0.6897 - val_accuracy: 0.8558 - lr: 5.7544e-06\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0455 - accuracy: 0.9852 - val_loss: 0.6696 - val_accuracy: 0.8546 - lr: 5.2481e-06\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 38s 27ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.7577 - val_accuracy: 0.8534 - lr: 4.7863e-06\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 38s 27ms/step - loss: 0.0320 - accuracy: 0.9894 - val_loss: 0.7673 - val_accuracy: 0.8534 - lr: 4.3652e-06\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 0.8264 - val_accuracy: 0.8546 - lr: 3.9811e-06\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.8427 - val_accuracy: 0.8552 - lr: 3.6308e-06\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.8940 - val_accuracy: 0.8506 - lr: 3.3113e-06\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.8464 - val_accuracy: 0.8588 - lr: 3.0200e-06\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.8612 - val_accuracy: 0.8558 - lr: 2.7542e-06\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.8967 - val_accuracy: 0.8632 - lr: 2.5119e-06\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.8946 - val_accuracy: 0.8596 - lr: 2.2909e-06\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.9304 - val_accuracy: 0.8638 - lr: 2.0893e-06\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.9665 - val_accuracy: 0.8594 - lr: 1.9055e-06\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.9307 - val_accuracy: 0.8600 - lr: 1.7378e-06\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.9625 - val_accuracy: 0.8612 - lr: 1.5849e-06\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.9847 - val_accuracy: 0.8610 - lr: 1.4454e-06\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.9992 - val_accuracy: 0.8644 - lr: 1.3183e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "69RYIFci4ST3",
        "outputId": "46f5b090-b36d-4771-bf55-9a8063fe3bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "its clear based on these results that a the VG19 model signficantly outpeformed a simple DNN for this problem. For me i am considering this problem solved. 86% acccuracy on validation is great! if i were to need a better solution to this problem i would experiment with using a different pre-train NN. "
      ],
      "metadata": {
        "id": "pmweAJsl3kVW"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CIFAR10",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}